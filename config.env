# =============================================================================
# LLM Watchdog Configuration for Gilbreth
# =============================================================================
# Model-specific settings live in models/*.env
# Switch models with:  ./switch-model.sh <model-name>
# Active model:        active-model.env -> models/<name>.env

# -----------------------------------------------------------------------------
# Notifications (ntfy.sh)
# -----------------------------------------------------------------------------
NTFY_TOPIC="purduechat-watchdog"
NTFY_SERVER="https://ntfy.sh"

# -----------------------------------------------------------------------------
# CUDA 13 Environment (used only when model sets REQUIRES_CUDA13=true)
# -----------------------------------------------------------------------------
# vllm._C.so links against libcudart.so.12, so we need CUDA 12.6 libs on
# LD_LIBRARY_PATH. But flashinfer FP8 block scaling requires CUDA >= 12.8,
# detected via nvcc at CUDA_HOME. We point CUDA_HOME to 13.1 and prepend
# the 12.6 lib64 path for the runtime library.
CUDA12_LIB="/apps/spack/gilbreth-r9/apps/cuda/12.6.0-gcc-11.5.0-a7cv7sp/lib64"
CUDA_HOME_OVERRIDE="/apps/external/cuda-toolkit/13.1.0"

# -----------------------------------------------------------------------------
# LLM Server (vLLM)
# -----------------------------------------------------------------------------
LLM_VENV="/home/dchawra/llm-watchdog/.venv"
LLM_BIN="${LLM_VENV}/bin/vllm"
SERVER_PORT="8000"
HF_HOME="/scratch/gilbreth/dchawra/cache/huggingface"

# -----------------------------------------------------------------------------
# Cloudflare Tunnel
# -----------------------------------------------------------------------------
CLOUDFLARED_BIN="/home/dchawra/cloudflared-linux-amd64"
TUNNEL_NAME="gilbreth"
TUNNEL_ID="0051dc2e-f4fb-4a69-8284-6c18d35514fe"
TUNNEL_HOSTNAME="purduechat.dwijen.dev"
CLOUDFLARED_CREDS="/home/dchawra/.cloudflared/${TUNNEL_ID}.json"

# -----------------------------------------------------------------------------
# Detection Settings
# -----------------------------------------------------------------------------
# Fast polling recommended for GPU workloads to minimize CUDA OOM risk
# 0.25s = ~1s worst case detection time
POLL_INTERVAL="0.25"
