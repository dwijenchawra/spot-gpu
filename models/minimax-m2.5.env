# =============================================================================
# MiniMax-M2.5  --  MiniMaxAI/MiniMax-M2.5
# =============================================================================
# MiniMax reasoning model with tool-calling support.
# Requires CUDA >= 12.8 for FP8 -- will fail on older nodes.

MODEL_NAME="/scratch/gilbreth/dchawra/models/MiniMax-M2.5"

export SAFETENSORS_FAST_GPU=1
export VLLM_FP8_MOE_BACKEND=DEEPGEMM
export PYTORCH_ALLOC_CONF="expandable_segments:True,max_split_size_mb:512"
export VLLM_SLEEP_WHEN_IDLE=0
export VLLM_ALLREDUCE_USE_SYMM_MEM=0

VLLM_ARGS="--trust-remote-code \
    --tensor-parallel-size 4 \
    --enable-expert-parallel \
    --enable-auto-tool-choice \
    --tool-call-parser minimax_m2 \
    --reasoning-parser minimax_m2 \
    --load-format fastsafetensors \
    --compilation-config '{\"cudagraph_mode\":\"PIECEWISE\"}' \
    --max-num-seqs 16 \
    --gpu-memory-utilization 0.95 \
    --served-model-name minimax-m2.5"
